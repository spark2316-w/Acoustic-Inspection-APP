import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.io import wavfile
from scipy.signal import correlate
from io import BytesIO
import tempfile

# ==== à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¹à¸›à¸¥à¸‡à¹„à¸Ÿà¸¥à¹Œ .wav à¹€à¸›à¹‡à¸™ normalized numpy ====
def audio_to_normalized_numpy(wav_path_or_bytes):
    sample_rate, samples = wavfile.read(wav_path_or_bytes)
    if samples.ndim > 1:
        samples = samples[:, 0]  # à¸–à¹‰à¸²à¹€à¸›à¹‡à¸™ stereo à¹€à¸­à¸²à¹à¸„à¹ˆ channel à¹à¸£à¸
    samples = samples.astype(np.float32)
    samples -= np.mean(samples)
    samples /= np.std(samples) + 1e-9
    return samples

# ==== UI à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² ====
st.set_page_config(page_title="ğŸ™ï¸ Real-time Audio Comparison", layout="wide")
st.title("ğŸ™ï¸ à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¹€à¸ªà¸µà¸¢à¸‡ Real-Time à¸à¸±à¸š Reference WAV")

st.markdown("à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ **à¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡ (.wav)** à¸ˆà¸²à¸à¸™à¸±à¹‰à¸™ **à¸šà¸±à¸™à¸—à¸¶à¸à¹€à¸ªà¸µà¸¢à¸‡à¸ˆà¸£à¸´à¸‡à¸œà¹ˆà¸²à¸™à¹„à¸¡à¹‚à¸„à¸£à¹‚à¸Ÿà¸™** à¹€à¸à¸·à¹ˆà¸­à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸„à¸§à¸²à¸¡à¸„à¸¥à¹‰à¸²à¸¢à¸„à¸¥à¸¶à¸‡")

# ==== Upload Reference File ====
reference_file = st.file_uploader("ğŸ“Œ à¸­à¸±à¸›à¹‚à¸«à¸¥à¸” Reference .wav", type=["wav"], key="ref_upload")

# ==== Audio Input ====
recorded_audio = st.audio_input("ğŸ¤ à¸šà¸±à¸™à¸—à¸¶à¸à¹€à¸ªà¸µà¸¢à¸‡à¸œà¹ˆà¸²à¸™à¹„à¸¡à¹‚à¸„à¸£à¹‚à¸Ÿà¸™ (Test Audio)", type="wav")

# ==== à¹€à¸¡à¸·à¹ˆà¸­à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸à¸£à¹‰à¸­à¸¡ ====
if reference_file and recorded_audio:
    st.success("âœ… à¹€à¸£à¸´à¹ˆà¸¡à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥")

    # à¹à¸›à¸¥à¸‡à¹„à¸Ÿà¸¥à¹Œà¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡
    ref_signal = audio_to_normalized_numpy(reference_file)

    # à¹à¸›à¸¥à¸‡à¹„à¸Ÿà¸¥à¹Œà¹€à¸ªà¸µà¸¢à¸‡à¸—à¸µà¹ˆà¸­à¸±à¸”à¸œà¹ˆà¸²à¸™à¹„à¸¡à¸„à¹Œ (à¸•à¹‰à¸­à¸‡à¸šà¸±à¸™à¸—à¸¶à¸à¹€à¸›à¹‡à¸™ temp file à¸à¹ˆà¸­à¸™)
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmpfile:
        tmpfile.write(recorded_audio.read())
        tmp_path = tmpfile.name

    test_signal = audio_to_normalized_numpy(tmp_path)

    # ==== à¸à¸¥à¹‡à¸­à¸•à¸ªà¸±à¸à¸à¸²à¸“ ====
    st.subheader("ğŸ”Š à¸ªà¸±à¸à¸à¸²à¸“à¹€à¸ªà¸µà¸¢à¸‡")
    fig, axs = plt.subplots(2, 1, figsize=(12, 6))
    axs[0].plot(ref_signal, color="blue")
    axs[0].set_title("Reference Signal")
    axs[1].plot(test_signal, color="red")
    axs[1].set_title("Recorded Test Signal")
    st.pyplot(fig)

    # ==== à¸„à¸³à¸™à¸§à¸“ Cross-Correlation ====
    cross_corr = correlate(ref_signal, test_signal, mode='full', method='auto')
    max_corr = np.max(cross_corr) / len(ref_signal)
    lags = np.arange(-(len(test_signal) - 1), len(ref_signal))

    fig2, ax2 = plt.subplots(figsize=(10, 4))
    ax2.plot(lags, cross_corr)
    ax2.set_title("Cross-Correlation")
    ax2.set_xlabel("Lag")
    ax2.set_ylabel("Correlation")
    ax2.grid(True)
    st.pyplot(fig2)

    # ==== à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸„à¸§à¸²à¸¡à¸„à¸¥à¹‰à¸²à¸¢à¸„à¸¥à¸¶à¸‡ ====
    if max_corr > 0.3:
        similarity = "âœ… Very Similar"
    elif max_corr > 0.2:
        similarity = "âš ï¸ Moderately Similar"
    else:
        similarity = "âŒ Not Similar"

    st.markdown(f"### ğŸ” à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œ: **{similarity}** (Max Corr = `{max_corr:.5f}`)")
